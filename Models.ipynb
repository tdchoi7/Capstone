{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from My_Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import gzip\n",
    "\n",
    "import import_ipynb\n",
    "from My_Functions import null_cols, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nonorm = pd.read_csv(\"acc_nonorm_touse.csv.gz\",\n",
    "                        compression='gzip',\n",
    "                        header=0,\n",
    "                        sep=',',\n",
    "                        quotechar='\"')\n",
    "\n",
    "acc_partialnorm = pd.read_csv(\"acc_partialnorm_touse.csv.gz\",\n",
    "                        compression='gzip',\n",
    "                        header=0,\n",
    "                        sep=',',\n",
    "                        quotechar='\"')\n",
    "\n",
    "acc_fullnorm = pd.read_csv(\"acc_fullnorm_touse.csv.gz\",\n",
    "                        compression='gzip',\n",
    "                        header=0,\n",
    "                        sep=',',\n",
    "                        quotechar='\"')\n",
    "\n",
    "target_touse = pd.read_csv(\"target_touse.csv.gz\",\n",
    "                           compression='gzip',\n",
    "                           header=0,\n",
    "                           sep=',',\n",
    "                           quotechar='\"')\n",
    "\n",
    "# acc_forprediction = pd.read_csv(\"acc_forprediction.csv.gz\",\n",
    "#                                 compression='gzip',\n",
    "#                                 header=0,\n",
    "#                                 sep=',',\n",
    "#                                 quotechar='\"')\n",
    "\n",
    "# target_forprediction = pd.read_csv(\"target_forprediction.csv.gz\",\n",
    "#                                    compression='gzip',\n",
    "#                                    header=0,\n",
    "#                                    sep=',',\n",
    "#                                    quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=0\n",
    "\n",
    "# nonorm:\n",
    "xtrain_no, xtest_no, ytrain_no, ytest_no = ms.train_test_split(acc_nonorm,\n",
    "                                                               target_touse,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=state)\n",
    "\n",
    "# Must flatten to fit\n",
    "ytrain_no = ytrain_no.values.flatten()\n",
    "\n",
    "\n",
    "# partialnorm:\n",
    "xtrain_partial, xtest_partial, ytrain_partial, ytest_partial = ms.train_test_split(acc_partialnorm,\n",
    "                                                                                   target_touse,\n",
    "                                                                                   test_size=0.2,\n",
    "                                                                                   random_state=state)\n",
    "\n",
    "# Must flatten to fit\n",
    "ytrain_partial = ytrain_partial.values.flatten()\n",
    "\n",
    "\n",
    "# fullnorm:\n",
    "xtrain_full, xtest_full, ytrain_full, ytest_full = ms.train_test_split(acc_fullnorm,\n",
    "                                                                       target_touse,\n",
    "                                                                       test_size=0.2,\n",
    "                                                                       random_state=state)\n",
    "\n",
    "# Must flatten to fit\n",
    "ytrain_full = ytrain_full.values.flatten()\n",
    "\n",
    "\n",
    "# using standard kfold split\n",
    "n_folds = ms.KFold(n_splits=5, random_state=state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# logistic = LogisticRegression()\n",
    "\n",
    "# train_scores = []\n",
    "# test_scores = []\n",
    "# train_rmse = []\n",
    "# test_rmse = []\n",
    "# best_par_list = []\n",
    "\n",
    "# penalties = ['l1', 'l2']\n",
    "# # duals = [False]\n",
    "# Cs = [0.001, 0.1, 1]\n",
    "# fitintercept = [True, False]\n",
    "# # classweight = [{'grade':2, 'sub_grade': 2}]\n",
    "# randomstate = [state]\n",
    "# solvers = ['liblinear']\n",
    "# # max_iters = [1e4]\n",
    "# verbose_ = [1]\n",
    "# warmstart = [True, False]\n",
    "# # njobs = [-1]\n",
    "# # l1_ratios = [0, 0.5, 1]\n",
    "\n",
    "# gparam_liblin = {'penalty': penalties,\n",
    "# #              'dual': duals,\n",
    "#              'C': Cs,\n",
    "#              'fit_intercept': fitintercept,\n",
    "# #              'class_weight': classweight,\n",
    "#              'random_state': randomstate,\n",
    "#              'solver': solvers,\n",
    "# #              'max_iter': max_iters,\n",
    "#              'verbose': verbose_,\n",
    "#              'warm_start': warmstart}\n",
    "# #              'n_jobs': njobs}\n",
    "# #           'l1_ratio': l1_ratios}\n",
    "\n",
    "\n",
    "# gs_liblin = ms.GridSearchCV(logistic, gparam_liblin, cv=n_folds, refit=True, n_jobs=-1,\n",
    "#                         scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "# %time gs_liblin.fit(xtrain, ytrain)\n",
    "\n",
    "# # setting up dataframe for results\n",
    "# train_scores.append(gs_liblin.best_estimator_.score(xtrain, ytrain))\n",
    "# test_scores.append(gs_liblin.best_estimator_.score(xtest, ytest))\n",
    "\n",
    "# # use rmse function from Self_Written_Functions_Sheet_Recover\n",
    "# train_rmse.append(rmse(gs_liblin, ytrain, xtrain))\n",
    "# test_rmse.append(rmse(gs_liblin, ytest, xtest))\n",
    "\n",
    "# # add the best parameters to the df\n",
    "# best_par_list.append(gs_liblin.best_params_)\n",
    "\n",
    "# # find the difference btwn the rmses\n",
    "# diff_rmse = np.subtract(train_rmse, test_rmse)\n",
    "\n",
    "# # create dataframe\n",
    "# list_results = [train_scores, test_scores, train_rmse, test_rmse, diff_rmse]\n",
    "# res_df = pd.DataFrame(list_results).T\n",
    "# res_df.columns = ['TrainScores', 'TestScores', 'TrainRMSE', 'TestRMSE', 'DiffRMSE']\n",
    "# best_par_df = pd.DataFrame(best_par_list)\n",
    "# res_df = pd.concat([res_df, best_par_df], axis=1, sort=False)\n",
    "\n",
    "# res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(ytrain, gs_liblin.predict(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(ytest, gs_liblin.predict(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdcho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [-0.59731753 -0.59731753 -0.59214414 -0.59214414         nan         nan\n",
      "         nan         nan -0.58413564 -0.58413564 -0.5849297  -0.5849297\n",
      "         nan         nan         nan         nan -0.58280194 -0.58280194\n",
      " -0.58320017 -0.58320017         nan         nan         nan         nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\tdcho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the train scores are non-finite: [-0.59718599 -0.59718599 -0.59184988 -0.59184988         nan         nan\n",
      "         nan         nan -0.5834465  -0.5834465  -0.58444387 -0.58444387\n",
      "         nan         nan         nan         nan -0.58190333 -0.58190333\n",
      " -0.58241049 -0.58241049         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Wall time: 24min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainScores</th>\n",
       "      <th>TestScores</th>\n",
       "      <th>TrainRMSE</th>\n",
       "      <th>TestRMSE</th>\n",
       "      <th>DiffRMSE</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>random_state</th>\n",
       "      <th>solver</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.661169</td>\n",
       "      <td>0.662069</td>\n",
       "      <td>0.582092</td>\n",
       "      <td>0.581318</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrainScores  TestScores  TrainRMSE  TestRMSE  DiffRMSE  C penalty  \\\n",
       "0     0.661169    0.662069   0.582092  0.581318  0.000774  1      l1   \n",
       "\n",
       "   random_state     solver  verbose  warm_start  \n",
       "0             0  liblinear        1        True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "train_rmse = []\n",
    "test_rmse = []\n",
    "best_par_list = []\n",
    "\n",
    "penalties = ['l1', 'l2', 'elasticnet', 'none']\n",
    "Cs = [0.001, 0.1, 1]\n",
    "randomstate = [state]\n",
    "solvers = ['liblinear']\n",
    "# max_iters = [1e4]\n",
    "verbose_ = [1]\n",
    "warmstart = [True, False]\n",
    "# njobs = [-1]\n",
    "# l1_ratios = [0, 0.5, 1]\n",
    "\n",
    "gparam_saga = {'penalty': penalties,\n",
    "               'C': Cs,\n",
    "               'random_state': randomstate,\n",
    "               'solver': solvers,\n",
    "#              'max_iter': max_iters,\n",
    "               'verbose': verbose_,\n",
    "               'warm_start': warmstart}\n",
    "#              'n_jobs': njobs}\n",
    "#           'l1_ratio': l1_ratios}\n",
    "\n",
    "\n",
    "gs_saga = ms.GridSearchCV(logistic, gparam_saga, cv=n_folds, refit=True, n_jobs=-1,\n",
    "                          scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "%time gs_saga.fit(xtrain_full, ytrain_full)\n",
    "\n",
    "# setting up dataframe for results\n",
    "train_scores.append(gs_saga.best_estimator_.score(xtrain_full, ytrain_full))\n",
    "test_scores.append(gs_saga.best_estimator_.score(xtest_full, ytest_full))\n",
    "\n",
    "\n",
    "# use rmse function from Self_Written_Functions_Sheet_Recover\n",
    "train_rmse.append(rmse(gs_saga, ytrain_full, xtrain_full))\n",
    "test_rmse.append(rmse(gs_saga, ytest_full, xtest_full))\n",
    "\n",
    "# add the best parameters to the df\n",
    "best_par_list.append(gs_saga.best_params_)\n",
    "\n",
    "# find the difference btwn the rmses\n",
    "diff_rmse = np.subtract(train_rmse, test_rmse)\n",
    "\n",
    "# create dataframe\n",
    "list_results = [train_scores, test_scores, train_rmse, test_rmse, diff_rmse]\n",
    "res_df = pd.DataFrame(list_results).T\n",
    "res_df.columns = ['TrainScores', 'TestScores', 'TrainRMSE', 'TestRMSE', 'DiffRMSE']\n",
    "best_par_df = pd.DataFrame(best_par_list)\n",
    "res_df = pd.concat([res_df, best_par_df], axis=1, sort=False)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71675, 36035],\n",
       "       [36979, 70799]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrain_full, gs_saga.predict(xtrain_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17917,  9053],\n",
       "       [ 9152, 17750]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest_full, gs_saga.predict(xtest_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdcho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 30 seconds\n",
      "Wall time: 2min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdcho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainScores</th>\n",
       "      <th>TestScores</th>\n",
       "      <th>TrainRMSE</th>\n",
       "      <th>TestRMSE</th>\n",
       "      <th>DiffRMSE</th>\n",
       "      <th>C</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>penalty</th>\n",
       "      <th>random_state</th>\n",
       "      <th>solver</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.661401</td>\n",
       "      <td>0.662682</td>\n",
       "      <td>0.581893</td>\n",
       "      <td>0.580791</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>sag</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrainScores  TestScores  TrainRMSE  TestRMSE  DiffRMSE      C  \\\n",
       "0     0.661401    0.662682   0.581893  0.580791  0.001102  0.001   \n",
       "\n",
       "   fit_intercept penalty  random_state solver  verbose  warm_start  \n",
       "0           True    none             0    sag        1        True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "train_rmse = []\n",
    "test_rmse = []\n",
    "best_par_list = []\n",
    "\n",
    "penalties = ['l2', 'none']\n",
    "# duals = [False]\n",
    "Cs = [0.001, 0.1, 1]\n",
    "fitintercept = [True, False]\n",
    "# classweight = [{'grade':2, 'sub_grade': 2}]\n",
    "randomstate = [state]\n",
    "solvers = ['sag']\n",
    "# max_iters = [1e4]\n",
    "verbose_ = [1]\n",
    "warmstart = [True, False]\n",
    "# njobs = [-1]\n",
    "# l1_ratios = [0, 0.5, 1]\n",
    "\n",
    "gparam_sag = {'penalty': penalties,\n",
    "#              'dual': duals,\n",
    "              'C': Cs,\n",
    "              'fit_intercept': fitintercept,\n",
    "#              'class_weight': classweight,\n",
    "              'random_state': randomstate,\n",
    "              'solver': solvers,\n",
    "#              'max_iter': max_iters,\n",
    "              'verbose': verbose_,\n",
    "              'warm_start': warmstart}\n",
    "#              'n_jobs': njobs}\n",
    "#           'l1_ratio': l1_ratios}\n",
    "\n",
    "\n",
    "gs_sag = ms.GridSearchCV(logistic, gparam_sag, cv=n_folds, refit=True, n_jobs=-1,\n",
    "                         scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "%time gs_sag.fit(xtrain_full, ytrain_full)\n",
    "\n",
    "# setting up dataframe for results\n",
    "train_scores.append(gs_sag.best_estimator_.score(xtrain_full, ytrain_full))\n",
    "test_scores.append(gs_sag.best_estimator_.score(xtest_full, ytest_full))\n",
    "\n",
    "# use rmse function from Self_Written_Functions_Sheet_Recover\n",
    "train_rmse.append(rmse(gs_sag, ytrain_full, xtrain_full))\n",
    "test_rmse.append(rmse(gs_sag, ytest_full, xtest_full))\n",
    "\n",
    "# add the best parameters to the df\n",
    "best_par_list.append(gs_sag.best_params_)\n",
    "\n",
    "# find the difference btwn the rmses\n",
    "diff_rmse = np.subtract(train_rmse, test_rmse)\n",
    "\n",
    "# create dataframe\n",
    "list_results = [train_scores, test_scores, train_rmse, test_rmse, diff_rmse]\n",
    "res_df = pd.DataFrame(list_results).T\n",
    "res_df.columns = ['TrainScores', 'TestScores', 'TrainRMSE', 'TestRMSE', 'DiffRMSE']\n",
    "best_par_df = pd.DataFrame(best_par_list)\n",
    "res_df = pd.concat([res_df, best_par_df], axis=1, sort=False)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71695, 36015],\n",
       "       [36949, 70829]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrain_full, gs_sag.predict(xtrain_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71695, 36015],\n",
       "       [36949, 70829]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrain_full, gs_sag.predict(xtrain_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdcho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan -0.59742426         nan\n",
      "         nan -0.59254665 -0.61828033 -0.61194485 -0.60212223 -0.59239746\n",
      " -0.64819536 -0.63392775 -0.62085013 -0.60483663 -0.60335671 -0.60335671\n",
      " -0.60055912 -0.59386847 -0.59742426 -0.59192716 -0.58785714 -0.57957793\n",
      " -0.61828033 -0.59977032 -0.59070528 -0.58404932 -0.64819536 -0.61379979\n",
      " -0.59853984 -0.58790989 -0.60335671 -0.60073654 -0.59195436 -0.58440125\n",
      " -0.59742426 -0.58761678 -0.5838878  -0.58689947 -0.61828033 -0.62115722\n",
      " -0.62473824 -0.61771136 -0.64819536 -0.62719687 -0.61674986 -0.61004085\n",
      " -0.62232634 -0.61493107 -0.60678408 -0.59440126 -0.62324484 -0.61478382\n",
      " -0.60685664 -0.5943896  -0.6216565  -0.61487439 -0.60684533 -0.59436221\n",
      " -0.62420753 -0.61503296 -0.60673047 -0.59437776 -0.61332828 -0.5947054\n",
      " -0.58802726 -0.58525932 -0.61455328 -0.59458082 -0.58798814 -0.58522383\n",
      " -0.61196821 -0.59493554 -0.58788994 -0.58525535 -0.6141161  -0.59445221\n",
      " -0.58808693 -0.58522368 -0.648411   -0.62535517 -0.66899835 -0.69225802\n",
      " -0.64958248 -0.64313236 -0.67329517 -0.67090054 -0.63603785 -0.65368945\n",
      " -0.64716709 -0.69216871 -0.63207835 -0.62049223 -0.67524595 -0.69052307]\n",
      "  warnings.warn(\n",
      "C:\\Users\\tdcho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the train scores are non-finite: [            nan             nan             nan             nan\n",
      " -5.95273252e-01             nan             nan -5.90204649e-01\n",
      " -4.80239578e-01 -4.50634535e-01 -4.13611623e-01 -3.69410699e-01\n",
      " -3.27962324e-01 -2.56119368e-01 -1.89751601e-01 -1.00431545e-01\n",
      " -6.03359936e-01 -6.03359936e-01 -6.00565417e-01 -5.93654375e-01\n",
      " -5.95273252e-01 -5.90285489e-01 -5.85048965e-01 -5.72773306e-01\n",
      " -4.80239578e-01 -3.91261848e-01 -3.10409460e-01 -1.96774129e-01\n",
      " -3.27962324e-01 -1.26594738e-01 -4.00208558e-02 -4.81697021e-04\n",
      " -6.03359936e-01 -6.00604039e-01 -5.90640073e-01 -5.82594405e-01\n",
      " -5.95273252e-01 -5.81423527e-01 -5.69163353e-01 -5.48468538e-01\n",
      " -4.80239578e-01 -3.72685475e-01 -1.81465186e-01 -9.63394043e-04\n",
      " -3.27962324e-01 -7.44860655e-03  0.00000000e+00  0.00000000e+00\n",
      " -6.21890697e-01 -6.14497926e-01 -6.06476475e-01 -5.93940697e-01\n",
      " -6.22973851e-01 -6.14556486e-01 -6.06471678e-01 -5.93930933e-01\n",
      " -6.21314115e-01 -6.14494100e-01 -6.06463069e-01 -5.93897723e-01\n",
      " -6.23992057e-01 -6.14537564e-01 -6.06455427e-01 -5.93927015e-01\n",
      " -6.12843833e-01 -5.94088143e-01 -5.87506689e-01 -5.84468653e-01\n",
      " -6.13497686e-01 -5.94063753e-01 -5.87704160e-01 -5.84535099e-01\n",
      " -6.11682161e-01 -5.94253089e-01 -5.87657768e-01 -5.84577770e-01\n",
      " -6.14586096e-01 -5.93940701e-01 -5.87629155e-01 -5.84478552e-01\n",
      " -6.48496658e-01 -6.25989390e-01 -6.69550943e-01 -6.92701064e-01\n",
      " -6.48576805e-01 -6.42417198e-01 -6.72105263e-01 -6.70723711e-01\n",
      " -6.34850899e-01 -6.53696183e-01 -6.46138035e-01 -6.92763727e-01\n",
      " -6.31730763e-01 -6.20580877e-01 -6.75566090e-01 -6.90719662e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainScores</th>\n",
       "      <th>TestScores</th>\n",
       "      <th>TrainRMSE</th>\n",
       "      <th>TestRMSE</th>\n",
       "      <th>DiffRMSE</th>\n",
       "      <th>booster</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.670144</td>\n",
       "      <td>0.664742</td>\n",
       "      <td>0.574331</td>\n",
       "      <td>0.579014</td>\n",
       "      <td>-0.004684</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrainScores  TestScores  TrainRMSE  TestRMSE  DiffRMSE booster  \\\n",
       "0     0.670144    0.664742   0.574331  0.579014 -0.004684  gbtree   \n",
       "\n",
       "   learning_rate  max_depth  n_estimators  \n",
       "0            0.1          5            50  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clsfr = xgb.XGBClassifier(objective='binary:logistic', random_state=state,\n",
    "                              eval_metric='rmse', use_label_encoder=False,\n",
    "#                               tree_method='gpu_hist', predictor='gpu_predictor',\n",
    "                              gamma=0.01)\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "train_rmse = []\n",
    "test_rmse = []\n",
    "best_par_list = []\n",
    "\n",
    "nestimators = [1, 5, 15, 50]\n",
    "booster_ = ['gbtree', 'gblinear']\n",
    "maxdepth = [1, 5, 15, 50]\n",
    "learningrate = [0.01, 0.1, 1]\n",
    "# gamma_ = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "\n",
    "gparam_xgb = {'n_estimators': nestimators,\n",
    "              'booster': booster_,\n",
    "              'max_depth': maxdepth,\n",
    "              'learning_rate': learningrate}\n",
    "#               'gamma': gamma_}\n",
    "\n",
    "gs_xgb = ms.GridSearchCV(xgb_clsfr, gparam_xgb, cv=n_folds, refit=True, n_jobs=-1,\n",
    "                         scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "%time gs_xgb.fit(xtrain_no, ytrain_no)\n",
    "\n",
    "# setting up dataframe for results\n",
    "train_scores.append(gs_xgb.best_estimator_.score(xtrain_no, ytrain_no))\n",
    "test_scores.append(gs_xgb.best_estimator_.score(xtest_no, ytest_no))\n",
    "\n",
    "# use rmse function from Self_Written_Functions_Sheet_Recover\n",
    "train_rmse.append(rmse(gs_xgb, ytrain_no, xtrain_no))\n",
    "test_rmse.append(rmse(gs_xgb, ytest_no, xtest_no))\n",
    "\n",
    "# add the best parameters to the df\n",
    "best_par_list.append(gs_xgb.best_params_)\n",
    "\n",
    "# find the difference btwn the rmses\n",
    "diff_rmse = np.subtract(train_rmse, test_rmse)\n",
    "\n",
    "# create dataframe\n",
    "list_results = [train_scores, test_scores, train_rmse, test_rmse, diff_rmse]\n",
    "res_df = pd.DataFrame(list_results).T\n",
    "res_df.columns = ['TrainScores', 'TestScores', 'TrainRMSE', 'TestRMSE', 'DiffRMSE']\n",
    "best_par_df = pd.DataFrame(best_par_list)\n",
    "res_df = pd.concat([res_df, best_par_df], axis=1, sort=False)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70144, 37566],\n",
       "       [33514, 74264]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrain_no, gs_xgb.predict(xtrain_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17349,  9621],\n",
       "       [ 8440, 18462]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest_no, gs_xgb.predict(xtest_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grade', 0.42365357),\n",
       " ('sub_grade', 0.17668334),\n",
       " ('term', 0.018636014),\n",
       " ('open_rv_24m', 0.018029213),\n",
       " ('home_ownership_RENT', 0.012181467),\n",
       " ('acc_open_past_24mths', 0.010916078),\n",
       " ('int_rate', 0.010462329),\n",
       " ('year', 0.010359949),\n",
       " ('dti', 0.009659388),\n",
       " ('avg_cur_bal', 0.008983572),\n",
       " ('all_util', 0.008613097),\n",
       " ('purpose_small_business', 0.008607892),\n",
       " ('mort_acc', 0.008442886),\n",
       " ('num_tl_120dpd_2m', 0.008056527),\n",
       " ('emp_length', 0.008012441),\n",
       " ('fico_range_low', 0.007887046),\n",
       " ('annual_inc', 0.0076512094),\n",
       " ('num_actv_rev_tl', 0.0073627904),\n",
       " ('month', 0.006974463),\n",
       " ('addr_state_WA', 0.006893026),\n",
       " ('addr_state_SC', 0.0068826987),\n",
       " ('home_ownership_MORTGAGE', 0.0068597193),\n",
       " ('mths_since_recent_inq', 0.0061105555),\n",
       " ('installment', 0.0061016087),\n",
       " ('addr_state_OR', 0.006045591),\n",
       " ('addr_state_CO', 0.0060269632),\n",
       " ('tot_hi_cred_lim', 0.005620666),\n",
       " ('sec_app_revol_util', 0.0050641466),\n",
       " ('funded_amnt', 0.004975227),\n",
       " ('delinq_2yrs', 0.0049588517),\n",
       " ('max_bal_bc', 0.0047628502),\n",
       " ('inq_last_6mths', 0.00468736),\n",
       " ('num_il_tl', 0.0045969537),\n",
       " ('funded_amnt_inv', 0.0044937343),\n",
       " ('num_rev_tl_bal_gt_0', 0.0044284947),\n",
       " ('revol_bal', 0.0044005457),\n",
       " ('total_bc_limit', 0.004377289),\n",
       " ('num_actv_bc_tl', 0.004339808),\n",
       " ('mo_sin_old_rev_tl_op', 0.0042460137),\n",
       " ('total_rev_hi_lim', 0.0042075645),\n",
       " ('sec_app_inq_last_6mths', 0.004124534),\n",
       " ('bc_open_to_buy', 0.004042478),\n",
       " ('mths_since_recent_bc', 0.004042223),\n",
       " ('addr_state_CA', 0.0037278626),\n",
       " ('total_il_high_credit_limit', 0.0033872968),\n",
       " ('addr_state_NJ', 0.002599253),\n",
       " ('purpose_major_purchase', 0.00259025),\n",
       " ('bc_util', 0.0025853903),\n",
       " ('sec_app_collections_12_mths_ex_med', 0.002574873),\n",
       " ('open_il_24m', 0.002552065),\n",
       " ('mths_since_last_delinq', 0.0025009627),\n",
       " ('mo_sin_rcnt_tl', 0.0024963547),\n",
       " ('addr_state_OK', 0.0024179136),\n",
       " ('verification_status_Verified', 0.002357843),\n",
       " ('duration_of_credit_months', 0.0023226223),\n",
       " ('num_bc_sats', 0.0022823126),\n",
       " ('tot_cur_bal', 0.0022505599),\n",
       " ('open_rv_12m', 0.002156254),\n",
       " ('open_acc_6m', 0.0021195768),\n",
       " ('sec_app_fico_range_low', 0.0021036756),\n",
       " ('percent_bc_gt_75', 0.0020739546),\n",
       " ('total_acc', 0.0020618),\n",
       " ('total_bal_ex_mort', 0.0020336525),\n",
       " ('revol_util', 0.0020092023),\n",
       " ('mo_sin_old_il_acct', 0.0020061864),\n",
       " ('num_tl_op_past_12m', 0.0019822652),\n",
       " ('total_bal_il', 0.0019200725),\n",
       " ('pub_rec_bankruptcies', 0.0018665438),\n",
       " ('mo_sin_rcnt_rev_tl_op', 0.0018650333),\n",
       " ('collections_12_mths_ex_med', 0.0018282635),\n",
       " ('annual_inc_joint', 0.0018237623),\n",
       " ('total_cu_tl', 0.0018173978),\n",
       " ('addr_state_GA', 0.0017691903),\n",
       " ('mths_since_last_major_derog', 0.0017383758),\n",
       " ('sec_app_open_acc', 0.0017268497),\n",
       " ('addr_state_RI', 0.001720719),\n",
       " ('dti_joint', 0.0016914051),\n",
       " ('num_bc_tl', 0.0016912905),\n",
       " ('num_accts_ever_120_pd', 0.0016661906),\n",
       " ('open_act_il', 0.0016382878),\n",
       " ('tax_liens', 0.0015869057),\n",
       " ('addr_state_OH', 0.0015169778),\n",
       " ('tot_coll_amt', 0.0015141296),\n",
       " ('inq_last_12m', 0.0014441833),\n",
       " ('sec_app_mort_acc', 0.00143695),\n",
       " ('mths_since_rcnt_il', 0.0014023727),\n",
       " ('il_util', 0.0013870598),\n",
       " ('mths_since_recent_revol_delinq', 0.0013405131),\n",
       " ('verification_status_Source Verified', 0.0013232679),\n",
       " ('addr_state_NC', 0.0013094748),\n",
       " ('pct_tl_nvr_dlq', 0.0012580582),\n",
       " ('sec_app_duration_of_credit_months', 0.0012321393),\n",
       " ('mths_since_recent_bc_dlq', 0.0012318775),\n",
       " ('addr_state_SD', 0.0011906028),\n",
       " ('num_op_rev_tl', 0.00118176),\n",
       " ('addr_state_VA', 0.0010216662),\n",
       " ('initial_list_status_w', 0.0010212259),\n",
       " ('num_rev_accts', 0.0008972922),\n",
       " ('open_acc', 0.00084471557),\n",
       " ('purpose_credit_card', 0.00080759724),\n",
       " ('mths_since_last_record', 0.00078032824),\n",
       " ('num_sats', 0.0007205207),\n",
       " ('revol_bal_joint', 0.00013266434),\n",
       " ('fico_range_high', 0.0),\n",
       " ('pub_rec', 0.0),\n",
       " ('policy_code', 0.0),\n",
       " ('acc_now_delinq', 0.0),\n",
       " ('open_il_12m', 0.0),\n",
       " ('inq_fi', 0.0),\n",
       " ('chargeoff_within_12_mths', 0.0),\n",
       " ('delinq_amnt', 0.0),\n",
       " ('num_tl_30dpd', 0.0),\n",
       " ('num_tl_90g_dpd_24m', 0.0),\n",
       " ('sec_app_fico_range_high', 0.0),\n",
       " ('sec_app_open_act_il', 0.0),\n",
       " ('sec_app_num_rev_accts', 0.0),\n",
       " ('sec_app_chargeoff_within_12_mths', 0.0),\n",
       " ('sec_app_mths_since_last_major_derog', 0.0),\n",
       " ('home_ownership_NONE', 0.0),\n",
       " ('home_ownership_OTHER', 0.0),\n",
       " ('home_ownership_OWN', 0.0),\n",
       " ('purpose_debt_consolidation', 0.0),\n",
       " ('purpose_educational', 0.0),\n",
       " ('purpose_home_improvement', 0.0),\n",
       " ('purpose_house', 0.0),\n",
       " ('purpose_medical', 0.0),\n",
       " ('purpose_moving', 0.0),\n",
       " ('purpose_other', 0.0),\n",
       " ('purpose_renewable_energy', 0.0),\n",
       " ('purpose_vacation', 0.0),\n",
       " ('purpose_wedding', 0.0),\n",
       " ('addr_state_AL', 0.0),\n",
       " ('addr_state_AR', 0.0),\n",
       " ('addr_state_AZ', 0.0),\n",
       " ('addr_state_CT', 0.0),\n",
       " ('addr_state_DC', 0.0),\n",
       " ('addr_state_DE', 0.0),\n",
       " ('addr_state_FL', 0.0),\n",
       " ('addr_state_HI', 0.0),\n",
       " ('addr_state_IA', 0.0),\n",
       " ('addr_state_ID', 0.0),\n",
       " ('addr_state_IL', 0.0),\n",
       " ('addr_state_IN', 0.0),\n",
       " ('addr_state_KS', 0.0),\n",
       " ('addr_state_KY', 0.0),\n",
       " ('addr_state_LA', 0.0),\n",
       " ('addr_state_MA', 0.0),\n",
       " ('addr_state_MD', 0.0),\n",
       " ('addr_state_ME', 0.0),\n",
       " ('addr_state_MI', 0.0),\n",
       " ('addr_state_MN', 0.0),\n",
       " ('addr_state_MO', 0.0),\n",
       " ('addr_state_MS', 0.0),\n",
       " ('addr_state_MT', 0.0),\n",
       " ('addr_state_ND', 0.0),\n",
       " ('addr_state_NE', 0.0),\n",
       " ('addr_state_NH', 0.0),\n",
       " ('addr_state_NM', 0.0),\n",
       " ('addr_state_NV', 0.0),\n",
       " ('addr_state_NY', 0.0),\n",
       " ('addr_state_PA', 0.0),\n",
       " ('addr_state_TN', 0.0),\n",
       " ('addr_state_TX', 0.0),\n",
       " ('addr_state_UT', 0.0),\n",
       " ('addr_state_VT', 0.0),\n",
       " ('addr_state_WI', 0.0),\n",
       " ('addr_state_WV', 0.0),\n",
       " ('addr_state_WY', 0.0),\n",
       " ('application_type_Joint App', 0.0),\n",
       " ('verification_status_joint_Not Verified', 0.0),\n",
       " ('verification_status_joint_Source Verified', 0.0),\n",
       " ('verification_status_joint_Verified', 0.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_importance = sorted(zip(xtrain_no.columns,\n",
    "                               gs_xgb.best_estimator_.feature_importances_),\n",
    "                           key=lambda t:t[1], reverse=True)\n",
    "sorted_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clsfr = xgb.XGBClassifier(objective='binary:logistic', random_state=state,\n",
    "                              eval_metric='rmse', use_label_encoder=False,\n",
    "                              tree_method='gpu_hist', predictor='gpu_predictor',\n",
    "                              gamma=0.01)\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "train_rmse = []\n",
    "test_rmse = []\n",
    "best_par_list = []\n",
    "\n",
    "nestimators = [1, 5, 15, 50]\n",
    "booster_ = ['gbtree', 'gblinear']\n",
    "maxdepth = [1, 5, 15, 50]\n",
    "learningrate = [0.01, 0.1, 1]\n",
    "# gamma_ = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "\n",
    "gparam_xgb = {'n_estimators': nestimators,\n",
    "              'booster': booster_,\n",
    "              'max_depth': maxdepth,\n",
    "              'learning_rate': learningrate}\n",
    "#               'gamma': gamma_}\n",
    "\n",
    "gs_xgb = ms.GridSearchCV(xgb_clsfr, gparam_xgb, cv=n_folds, refit=True, n_jobs=-1,\n",
    "                         scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "%time gs_xgb.fit(xtrain_partial, ytrain_partial)\n",
    "\n",
    "# setting up dataframe for results\n",
    "train_scores.append(gs_xgb.best_estimator_.score(xtrain_partial, ytrain_partial))\n",
    "test_scores.append(gs_xgb.best_estimator_.score(xtest_partial, ytest_partial))\n",
    "\n",
    "# use rmse function from Self_Written_Functions_Sheet_Recover\n",
    "train_rmse.append(rmse(gs_xgb, ytrain_partial, xtrain_partial))\n",
    "test_rmse.append(rmse(gs_xgb, ytest_partial, xtest_partial))\n",
    "\n",
    "# add the best parameters to the df\n",
    "best_par_list.append(gs_xgb.best_params_)\n",
    "\n",
    "# find the difference btwn the rmses\n",
    "diff_rmse = np.subtract(train_rmse, test_rmse)\n",
    "\n",
    "# create dataframe\n",
    "list_results = [train_scores, test_scores, train_rmse, test_rmse, diff_rmse]\n",
    "res_df = pd.DataFrame(list_results).T\n",
    "res_df.columns = ['TrainScores', 'TestScores', 'TrainRMSE', 'TestRMSE', 'DiffRMSE']\n",
    "best_par_df = pd.DataFrame(best_par_list)\n",
    "res_df = pd.concat([res_df, best_par_df], axis=1, sort=False)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytrain_partial, gs_xgb.predict(xtrain_partial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytest_partial, gs_xgb.predict(xtest_partial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importance = sorted(zip(xtrain_partial.columns,\n",
    "                               gs_xgb.best_estimator_.feature_importances_),\n",
    "                           key=lambda t:t[1], reverse=True)\n",
    "sorted_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clsfr = xgb.XGBClassifier(objective='binary:logistic', random_state=state,\n",
    "                              eval_metric='rmse', use_label_encoder=False,\n",
    "                              tree_method='gpu_hist', predictor='gpu_predictor',\n",
    "                              gamma=0.01)\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "train_rmse = []\n",
    "test_rmse = []\n",
    "best_par_list = []\n",
    "\n",
    "nestimators = [1, 5, 15, 50]\n",
    "booster_ = ['gbtree', 'gblinear']\n",
    "maxdepth = [1, 5, 15, 50]\n",
    "learningrate = [0.01, 0.1, 1]\n",
    "# gamma_ = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "\n",
    "gparam_xgb = {'n_estimators': nestimators,\n",
    "              'booster': booster_,\n",
    "              'max_depth': maxdepth,\n",
    "              'learning_rate': learningrate}\n",
    "#               'gamma': gamma_}\n",
    "\n",
    "gs_xgb = ms.GridSearchCV(xgb_clsfr, gparam_xgb, cv=n_folds, refit=True, n_jobs=-1,\n",
    "                         scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "%time gs_xgb.fit(xtrain_full, ytrain_full)\n",
    "\n",
    "# setting up dataframe for results\n",
    "train_scores.append(gs_xgb.best_estimator_.score(xtrain_full, ytrain_full))\n",
    "test_scores.append(gs_xgb.best_estimator_.score(xtest_full, ytest_full))\n",
    "\n",
    "# use rmse function from Self_Written_Functions_Sheet_Recover\n",
    "train_rmse.append(rmse(gs_xgb, ytrain_full, xtrain_full))\n",
    "test_rmse.append(rmse(gs_xgb, ytest_full, xtest_full))\n",
    "\n",
    "# add the best parameters to the df\n",
    "best_par_list.append(gs_xgb.best_params_)\n",
    "\n",
    "# find the difference btwn the rmses\n",
    "diff_rmse = np.subtract(train_rmse, test_rmse)\n",
    "\n",
    "# create dataframe\n",
    "list_results = [train_scores, test_scores, train_rmse, test_rmse, diff_rmse]\n",
    "res_df = pd.DataFrame(list_results).T\n",
    "res_df.columns = ['TrainScores', 'TestScores', 'TrainRMSE', 'TestRMSE', 'DiffRMSE']\n",
    "best_par_df = pd.DataFrame(best_par_list)\n",
    "res_df = pd.concat([res_df, best_par_df], axis=1, sort=False)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytrain_full, gs_xgb.predict(xtrain_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytest_full, gs_xgb.predict(xtest_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importance = sorted(zip(xtrain_full.columns,\n",
    "                               gs_xgb.best_estimator_.feature_importances_),\n",
    "                           key=lambda t:t[1], reverse=True)\n",
    "sorted_importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
